{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidad del Valle de Guatemala<br/>Introduccion a la Inteligencia Artificial\n",
    "## Dieter de Wit 15146\n",
    "\n",
    "# Hoja de Trabajo<br/>Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Imports\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import functools as ft\n",
    "from scipy import optimize\n",
    "\n",
    "# Internal Imports\n",
    "import load_mnist as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparamos la data para ser analizada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data in Mnist format\n",
    "X_train, y_train = lm.load_mnist('data/fashion')\n",
    "\n",
    "# Translate y_train into np.array\n",
    "y_train = np.array([y_train]).T\n",
    "\n",
    "# Construct the dataset with X_train and y_train values\n",
    "dataset = np.append(X_train.astype(float), y_train, 1)\n",
    "\n",
    "# Select a Training Sample\n",
    "training_value = int(len(dataset)*0.6)\n",
    "training = dataset[:training_value, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data in CSV format\n",
    "train_set = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "test_set = pd.read_csv('data/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the data, only X values\n",
    "x1 = train_set.iloc[:, 1:]/1000.0\n",
    "m1, n1 = x1.shape\n",
    "\n",
    "# Convert data from Train datasets into an array\n",
    "X = np.asarray(x1)\n",
    "m, n = X.shape\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Presenting Y data in array\n",
    "y = np.asarray(train_set.iloc[:, 0])\n",
    "y = y.reshape(m, 1)\n",
    "Y = (y == np.array(range(10))).astype(int)\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar la estructura de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99, 785],\n",
       "       [ 10, 100]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network Structure \n",
    "NN_Structure = np.array([n, 99, 10])\n",
    "\n",
    "# Thetas structure, later used for creating the Weight Matrix\n",
    "theta_structure = np.hstack((\n",
    "    NN_Structure[1:].reshape(len(NN_Structure) - 1, 1),\n",
    "    (NN_Structure[:-1] + 1).reshape(len(NN_Structure) - 1, 1)\n",
    "))\n",
    "\n",
    "theta_structure\n",
    "# Output shows:\n",
    "# 1 Inner layer with 99 Neurons\n",
    "# 1 Output Layer with 10 Neurons\n",
    "# 1 Initial layer with 784 Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar la estructura de los thetas a optimizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.95202301, 0.63406304, 0.8106702 , ..., 0.29735926, 0.20934463,\n",
       "         0.51093317],\n",
       "        [0.08205102, 0.3608362 , 0.4404341 , ..., 0.34437722, 0.38252149,\n",
       "         0.50060532],\n",
       "        [0.79012085, 0.59427233, 0.65302382, ..., 0.49636641, 0.96632502,\n",
       "         0.94559169],\n",
       "        ...,\n",
       "        [0.32620488, 0.76304164, 0.93087987, ..., 0.58761384, 0.40104465,\n",
       "         0.05699448],\n",
       "        [0.34756962, 0.19129413, 0.20267145, ..., 0.94953158, 0.05911504,\n",
       "         0.31974304],\n",
       "        [0.43922009, 0.16817778, 0.84851547, ..., 0.4064552 , 0.10123785,\n",
       "         0.63674218]]),\n",
       " array([[7.14838336e-01, 9.12245524e-01, 1.27760222e-01, 6.57377866e-01,\n",
       "         6.32000964e-01, 7.31646568e-01, 6.12246878e-01, 1.86927993e-01,\n",
       "         2.98988895e-02, 2.39257548e-01, 9.55286680e-01, 2.10790715e-01,\n",
       "         7.40069347e-01, 4.07962568e-01, 8.70329899e-01, 4.85046411e-01,\n",
       "         4.00600111e-01, 8.53843541e-03, 7.18476542e-01, 7.13952425e-01,\n",
       "         8.65541877e-01, 4.16099439e-01, 8.21915558e-01, 9.43189554e-01,\n",
       "         1.93671346e-01, 9.76877833e-01, 7.85871502e-01, 3.18474409e-01,\n",
       "         6.50793961e-01, 9.30105739e-01, 5.01346016e-04, 1.00927975e-01,\n",
       "         1.88508587e-02, 2.92545537e-01, 4.22431654e-02, 1.55209173e-02,\n",
       "         8.96756154e-01, 7.65977625e-01, 1.20951513e-01, 7.64467318e-01,\n",
       "         8.48460923e-01, 9.67759873e-01, 6.81683708e-01, 1.84462153e-01,\n",
       "         5.43866356e-01, 4.47240242e-01, 8.06274930e-03, 3.70387228e-01,\n",
       "         3.99828509e-01, 9.38100642e-01, 3.95737745e-01, 3.46364529e-02,\n",
       "         5.77492167e-01, 2.96903664e-01, 1.80607061e-02, 5.39528572e-01,\n",
       "         8.29656611e-01, 6.56618968e-01, 5.93274303e-02, 7.40739850e-01,\n",
       "         6.61858671e-01, 5.55827272e-01, 2.47389101e-01, 5.03001413e-01,\n",
       "         3.70183965e-01, 9.10195408e-03, 3.49223303e-01, 9.86784685e-01,\n",
       "         6.40006485e-01, 9.89573241e-01, 4.36940661e-01, 4.33023559e-01,\n",
       "         7.83702116e-01, 7.61173900e-01, 6.51089772e-02, 5.97918653e-01,\n",
       "         2.03274856e-01, 5.85723985e-01, 7.53423099e-01, 8.47182041e-01,\n",
       "         8.56853095e-01, 6.43302653e-01, 1.01616786e-01, 3.22172638e-01,\n",
       "         9.71576812e-01, 1.04663991e-01, 8.81777273e-01, 4.35462633e-01,\n",
       "         6.63996227e-01, 8.08328779e-01, 9.87568319e-01, 4.76202321e-01,\n",
       "         3.01200802e-02, 6.34433644e-01, 4.58888292e-01, 8.06778390e-01,\n",
       "         6.89153140e-01, 9.50762332e-01, 1.15697328e-01, 7.79779481e-02],\n",
       "        [4.81665585e-02, 8.75527416e-03, 1.86108442e-01, 4.68414771e-01,\n",
       "         6.29003553e-01, 9.77745069e-01, 8.68454063e-01, 4.83964920e-01,\n",
       "         7.68734530e-01, 1.55002566e-01, 8.08756811e-01, 5.63370051e-01,\n",
       "         1.08162077e-01, 6.79140041e-02, 1.07872734e-01, 3.51852291e-01,\n",
       "         2.12753077e-01, 9.90121859e-01, 5.27416324e-01, 7.23219061e-01,\n",
       "         7.14342582e-01, 6.65328968e-01, 9.21284948e-01, 2.30929723e-01,\n",
       "         3.87447087e-01, 5.94354699e-01, 2.38913886e-01, 5.66267868e-01,\n",
       "         4.83450714e-01, 5.62967344e-01, 8.66708320e-01, 4.36630712e-01,\n",
       "         6.83156941e-02, 8.93113950e-01, 3.36879014e-01, 8.81356711e-01,\n",
       "         5.31092281e-01, 1.32842644e-01, 1.26524005e-01, 4.97925689e-01,\n",
       "         1.94858618e-01, 8.27667033e-01, 7.10344771e-01, 9.33514713e-01,\n",
       "         2.00836759e-01, 9.10211431e-01, 4.99351442e-01, 1.01732996e-01,\n",
       "         3.78808704e-01, 3.90645196e-01, 2.35915864e-01, 7.95756194e-01,\n",
       "         5.61132421e-01, 8.00963807e-01, 8.18425658e-01, 4.18060528e-01,\n",
       "         5.51569177e-02, 9.57495592e-01, 6.12359472e-01, 4.51963615e-01,\n",
       "         8.47543633e-01, 1.26395188e-01, 7.54929380e-01, 1.91420413e-01,\n",
       "         9.17204383e-01, 1.91154698e-01, 5.86919762e-01, 7.66055996e-01,\n",
       "         5.24341900e-01, 8.30059733e-01, 6.16825865e-01, 3.28286667e-01,\n",
       "         4.76789783e-01, 1.78549039e-01, 5.68057689e-01, 1.22256612e-01,\n",
       "         4.39329326e-01, 6.10625486e-01, 6.45335033e-01, 9.39442621e-01,\n",
       "         2.76799439e-01, 7.76176291e-01, 5.03814392e-01, 1.66186427e-02,\n",
       "         5.37579732e-01, 4.56124046e-01, 1.30793217e-02, 3.61270509e-01,\n",
       "         4.41221232e-01, 1.64298320e-02, 8.59552849e-01, 5.68042275e-01,\n",
       "         2.13396580e-03, 6.33623915e-01, 2.39249090e-01, 4.80962213e-01,\n",
       "         6.79040210e-01, 8.08970729e-01, 6.51409257e-01, 4.92956052e-02],\n",
       "        [1.68677144e-01, 5.26372935e-01, 6.95736176e-02, 7.28886251e-01,\n",
       "         8.34448422e-01, 4.50510886e-01, 4.15322107e-02, 5.43992018e-01,\n",
       "         1.98393756e-01, 6.55152373e-01, 2.51742460e-01, 6.07622841e-01,\n",
       "         2.03850796e-02, 7.90760925e-01, 4.65576738e-01, 3.68289033e-01,\n",
       "         5.06161048e-01, 7.01452834e-01, 6.90021891e-01, 7.45138548e-01,\n",
       "         8.42977582e-01, 5.96121100e-01, 8.39419670e-01, 3.63225297e-02,\n",
       "         9.47341472e-01, 1.73052449e-01, 7.71275948e-01, 6.17115518e-01,\n",
       "         4.10681538e-01, 8.96477082e-01, 8.35658111e-01, 2.19629018e-01,\n",
       "         6.77975797e-01, 5.41569897e-01, 9.49729695e-01, 2.50004836e-01,\n",
       "         9.34669458e-01, 3.05109681e-01, 9.67394116e-01, 3.68135182e-01,\n",
       "         7.89504781e-01, 5.13928421e-01, 4.91676843e-01, 9.99315626e-01,\n",
       "         5.71473016e-01, 4.53399909e-01, 6.04895200e-01, 3.96242725e-01,\n",
       "         9.48193273e-01, 8.48154601e-01, 6.95528049e-01, 5.52388557e-01,\n",
       "         3.53930762e-01, 3.79635464e-01, 4.07136070e-01, 4.58078879e-01,\n",
       "         5.93090252e-01, 1.73645097e-01, 8.05836902e-01, 4.11797481e-01,\n",
       "         6.34448791e-01, 2.08582445e-01, 4.46763600e-01, 1.25421897e-01,\n",
       "         4.98306239e-01, 9.85782672e-01, 4.06582311e-01, 6.09272958e-01,\n",
       "         6.24243131e-01, 2.20955009e-01, 9.86153666e-01, 9.65225967e-01,\n",
       "         3.46302348e-01, 6.05497598e-01, 9.48991146e-01, 4.77972328e-03,\n",
       "         4.99859106e-01, 8.27913787e-01, 7.07108902e-02, 8.62998465e-01,\n",
       "         2.90287232e-01, 3.09335755e-01, 5.65582606e-01, 9.94683082e-01,\n",
       "         2.09727147e-01, 4.94256401e-01, 6.17385059e-01, 6.15710584e-01,\n",
       "         4.38522878e-01, 5.82594024e-01, 7.01480826e-01, 5.97730848e-01,\n",
       "         9.33776010e-01, 2.37044527e-01, 3.21900808e-01, 7.11988736e-01,\n",
       "         9.42526922e-01, 5.67582184e-01, 7.21149382e-01, 8.14276914e-01],\n",
       "        [5.96080681e-01, 9.66612228e-01, 4.69327287e-01, 7.89152544e-02,\n",
       "         8.79170060e-01, 9.45244277e-01, 8.67135847e-01, 7.16007311e-01,\n",
       "         3.65369909e-01, 7.64951521e-01, 1.50176988e-01, 3.28270636e-01,\n",
       "         2.60162172e-01, 1.87734513e-01, 9.77981512e-01, 7.48865542e-01,\n",
       "         7.58446473e-01, 2.53125934e-01, 3.42284578e-01, 3.53914542e-01,\n",
       "         8.03838554e-01, 7.52975216e-01, 9.65670319e-01, 2.51466846e-01,\n",
       "         6.87565183e-01, 4.74292345e-01, 7.17861421e-01, 3.78466388e-01,\n",
       "         3.64421536e-01, 5.47410266e-01, 2.00839222e-01, 4.68481305e-01,\n",
       "         9.52993071e-01, 3.94092646e-01, 5.65622302e-01, 6.97797105e-01,\n",
       "         8.56072427e-01, 3.74208027e-01, 3.77336102e-01, 9.76506197e-01,\n",
       "         9.11324127e-01, 7.22931000e-01, 6.77674544e-01, 1.41436742e-01,\n",
       "         1.16405459e-01, 2.82545555e-01, 6.67685183e-01, 1.99626356e-01,\n",
       "         5.43220156e-01, 4.40937290e-01, 2.80284015e-02, 9.25196312e-01,\n",
       "         1.00553904e-02, 5.57814537e-01, 1.24739503e-01, 1.52301716e-01,\n",
       "         7.76817090e-01, 7.52672966e-01, 8.99786380e-01, 6.27481491e-01,\n",
       "         3.87178279e-02, 2.55326800e-02, 3.46113326e-01, 3.23176141e-01,\n",
       "         7.23142829e-01, 1.61993317e-02, 2.96425500e-01, 5.43310187e-01,\n",
       "         5.10697270e-01, 8.85318717e-01, 2.58842301e-01, 8.81119942e-01,\n",
       "         7.32449477e-02, 4.37695157e-01, 5.24899441e-02, 4.48746201e-01,\n",
       "         3.81172754e-01, 5.97081405e-01, 9.84534366e-01, 4.43219019e-01,\n",
       "         8.79178996e-01, 3.02496546e-01, 5.78538746e-01, 4.90838011e-01,\n",
       "         5.32766768e-01, 4.02042651e-01, 9.47653399e-01, 3.08607953e-01,\n",
       "         6.57990429e-01, 5.14242575e-01, 9.36184859e-01, 5.75863044e-01,\n",
       "         3.16639088e-01, 5.89386085e-01, 2.99246606e-01, 6.01557973e-01,\n",
       "         5.36652589e-03, 9.28658964e-01, 3.22863835e-01, 6.57616605e-01],\n",
       "        [8.13781312e-01, 5.60355039e-01, 4.70972447e-01, 6.39635575e-01,\n",
       "         5.79182235e-01, 9.50699217e-02, 8.00135964e-01, 9.99058840e-01,\n",
       "         5.76333487e-02, 5.07916533e-01, 8.54121718e-01, 5.74486873e-01,\n",
       "         7.95374285e-01, 7.97322196e-01, 2.95525470e-01, 9.72455870e-01,\n",
       "         5.78850624e-01, 6.46075723e-01, 4.91936919e-01, 3.18720775e-01,\n",
       "         9.96893949e-01, 8.52305124e-01, 6.66833602e-02, 1.67334866e-01,\n",
       "         6.58399779e-01, 6.31586103e-01, 3.73603513e-01, 4.95866613e-01,\n",
       "         8.94480996e-01, 2.49126933e-01, 6.41572789e-01, 9.85114957e-01,\n",
       "         3.32247383e-01, 2.46684618e-01, 2.58576433e-01, 4.02634900e-01,\n",
       "         6.25257439e-01, 2.14867673e-01, 2.64965132e-01, 9.74858913e-01,\n",
       "         5.95924538e-01, 9.35472950e-01, 3.12939296e-01, 1.88320413e-01,\n",
       "         5.70245099e-01, 5.02584852e-01, 1.08110266e-02, 8.55922682e-01,\n",
       "         3.71736596e-01, 6.47533407e-01, 8.07350341e-02, 3.67119770e-01,\n",
       "         5.65616037e-01, 5.23927122e-01, 9.87853226e-01, 4.96498566e-01,\n",
       "         5.02429345e-01, 6.65178652e-01, 3.34346954e-01, 4.00494995e-01,\n",
       "         4.21757275e-01, 7.90289183e-01, 9.55493955e-01, 2.99914546e-02,\n",
       "         1.95558432e-01, 7.09665647e-01, 9.16487255e-01, 6.48839039e-01,\n",
       "         2.95186357e-01, 6.90500377e-01, 8.97478484e-01, 1.45787621e-01,\n",
       "         3.81112196e-01, 2.08160444e-01, 1.32958314e-01, 6.61089716e-01,\n",
       "         7.99627993e-01, 7.88824002e-01, 6.63060737e-01, 4.91157448e-01,\n",
       "         6.00784470e-01, 4.18641053e-01, 6.22042154e-01, 3.78145215e-01,\n",
       "         6.85627734e-01, 2.75915175e-01, 4.63977651e-01, 2.82993417e-02,\n",
       "         6.22816167e-01, 2.14504776e-01, 5.93673263e-01, 6.37593618e-01,\n",
       "         5.84138931e-01, 9.16589785e-01, 1.20457283e-01, 5.97453370e-01,\n",
       "         8.96747144e-01, 9.90425505e-01, 9.16115553e-01, 9.83883973e-01],\n",
       "        [3.42815764e-01, 8.38824984e-01, 3.34078173e-02, 3.81670156e-01,\n",
       "         4.62800097e-01, 7.59123734e-02, 3.09644237e-01, 4.79546026e-01,\n",
       "         5.69985666e-01, 8.40370821e-01, 8.32307083e-01, 4.03333026e-01,\n",
       "         8.34721423e-01, 5.11275004e-01, 8.53880019e-01, 3.85361645e-01,\n",
       "         1.63620646e-01, 6.80944959e-01, 6.03255743e-01, 1.86394013e-01,\n",
       "         8.36929521e-01, 3.59751474e-01, 3.66802157e-01, 2.73231337e-01,\n",
       "         5.99573313e-01, 6.60610482e-01, 3.14318906e-01, 7.51717389e-01,\n",
       "         9.67217711e-01, 4.03111962e-01, 1.79146293e-01, 2.88332128e-01,\n",
       "         4.48635641e-01, 5.84768311e-01, 5.71666315e-01, 2.44144138e-01,\n",
       "         6.80882981e-01, 4.32301968e-02, 8.76625765e-01, 4.94823876e-01,\n",
       "         1.89944940e-01, 4.09539170e-01, 9.57598353e-01, 6.98128880e-01,\n",
       "         4.19865087e-01, 9.65390326e-01, 3.07538930e-01, 8.06195212e-01,\n",
       "         8.06578457e-01, 7.96761078e-01, 2.10394276e-01, 3.22858456e-02,\n",
       "         7.36617362e-01, 7.79154799e-02, 1.28264818e-01, 6.29105250e-01,\n",
       "         5.64520185e-01, 6.70912364e-01, 1.02591090e-01, 9.56538924e-01,\n",
       "         1.17325589e-02, 1.12122427e-01, 6.93853159e-01, 2.77955761e-01,\n",
       "         4.92244797e-01, 2.96197722e-01, 3.60747546e-01, 3.07766298e-01,\n",
       "         5.72462423e-01, 1.43017120e-01, 3.39437294e-01, 1.74756484e-01,\n",
       "         4.85138583e-01, 9.05876376e-01, 2.57457804e-01, 7.26510068e-01,\n",
       "         7.68595731e-01, 5.41254990e-01, 9.35362036e-01, 8.09389767e-01,\n",
       "         3.94440342e-01, 4.21995134e-01, 2.64444792e-01, 9.94205966e-01,\n",
       "         7.36935875e-01, 2.96580788e-01, 9.33197541e-01, 8.14332956e-01,\n",
       "         1.28306061e-01, 4.11734268e-01, 4.93389398e-01, 8.35069927e-01,\n",
       "         4.00563574e-01, 7.55583925e-01, 9.38412835e-01, 6.43841581e-02,\n",
       "         1.67948223e-01, 9.55664721e-01, 3.09676574e-01, 5.06219901e-01],\n",
       "        [3.22323845e-01, 8.89399061e-01, 8.63050801e-01, 2.77405620e-02,\n",
       "         1.62180937e-01, 2.56667643e-01, 2.51988371e-01, 2.70329419e-01,\n",
       "         4.97675082e-02, 8.20079000e-01, 9.22880705e-01, 5.34359772e-01,\n",
       "         4.93317846e-01, 2.30794363e-01, 6.85654893e-01, 9.43248448e-01,\n",
       "         2.90456490e-01, 9.64573640e-02, 8.24710341e-01, 6.97646895e-01,\n",
       "         1.30179726e-01, 9.25764484e-01, 7.60682931e-01, 5.68384361e-01,\n",
       "         7.59512734e-02, 9.54048039e-01, 2.30115550e-01, 3.90254821e-01,\n",
       "         6.24137546e-01, 9.00487184e-01, 9.16988416e-01, 8.49541091e-01,\n",
       "         7.98901706e-01, 7.88097898e-01, 3.39388331e-02, 7.90525734e-01,\n",
       "         4.24830809e-01, 7.10770275e-01, 8.62768085e-01, 2.21365418e-01,\n",
       "         8.93104167e-01, 8.90272736e-01, 4.79721499e-01, 1.85938973e-01,\n",
       "         1.36018088e-01, 7.48746956e-01, 1.05942027e-01, 3.66319540e-01,\n",
       "         6.25767107e-01, 7.94531158e-01, 2.22017008e-01, 3.45466682e-01,\n",
       "         8.22082282e-01, 7.26657291e-01, 2.44842399e-02, 9.84999061e-01,\n",
       "         1.25843049e-01, 9.02798111e-01, 8.03672246e-01, 7.80146239e-01,\n",
       "         6.51700534e-01, 9.18137635e-01, 6.11525297e-01, 4.80118246e-01,\n",
       "         6.44026051e-01, 1.12124462e-01, 9.12654690e-01, 6.68562189e-01,\n",
       "         5.67183235e-01, 7.57735751e-01, 5.28634413e-01, 5.81605247e-01,\n",
       "         7.82801509e-01, 3.57045623e-01, 5.96557818e-01, 8.06162081e-01,\n",
       "         8.56247329e-01, 1.38887912e-01, 1.94006331e-01, 8.51519663e-01,\n",
       "         5.69631392e-01, 3.30547792e-01, 9.15671668e-01, 4.15472076e-01,\n",
       "         3.20590081e-01, 3.62623414e-01, 6.30971219e-01, 1.36738338e-01,\n",
       "         8.23391885e-01, 6.96765535e-01, 4.47253016e-01, 1.14189208e-01,\n",
       "         2.48713265e-01, 5.64742235e-01, 8.75025508e-02, 8.52369308e-01,\n",
       "         5.22666730e-01, 9.38072572e-01, 8.92966854e-01, 8.01033877e-01],\n",
       "        [2.74487291e-01, 8.06444943e-01, 4.51376782e-01, 7.40220063e-01,\n",
       "         8.87978438e-01, 7.31746656e-01, 8.98931896e-01, 4.63360042e-02,\n",
       "         4.03103361e-01, 5.74557243e-01, 6.42344752e-01, 9.17285889e-01,\n",
       "         5.91417566e-01, 1.61712182e-01, 8.16113001e-01, 8.30443861e-02,\n",
       "         2.55208921e-01, 6.38283767e-01, 4.06348400e-01, 6.26432923e-01,\n",
       "         9.73124436e-01, 1.81069084e-01, 2.40986224e-01, 2.27709414e-01,\n",
       "         2.96997962e-01, 7.57460997e-01, 1.08153130e-01, 7.51739470e-01,\n",
       "         6.49492028e-01, 7.22859510e-01, 2.84136183e-01, 5.64763549e-01,\n",
       "         1.84122444e-01, 8.40791225e-01, 6.62832262e-01, 5.46752912e-01,\n",
       "         4.07489870e-01, 7.61121912e-01, 9.64382759e-01, 3.91137124e-01,\n",
       "         7.11805048e-01, 9.14982702e-01, 9.69251336e-01, 6.04471543e-01,\n",
       "         8.28541744e-01, 5.18085457e-01, 9.47233609e-01, 7.79113117e-01,\n",
       "         8.81015170e-01, 1.29549982e-01, 3.30449920e-01, 4.02599368e-01,\n",
       "         7.84075931e-01, 5.28833877e-02, 3.64622223e-01, 8.20671300e-01,\n",
       "         6.13691353e-01, 9.44337374e-01, 4.52565389e-01, 8.62947122e-01,\n",
       "         9.84823088e-01, 4.40524522e-01, 5.01537765e-01, 1.85481076e-01,\n",
       "         3.25306375e-01, 3.54526355e-01, 4.58098128e-01, 9.94736030e-01,\n",
       "         6.18196153e-01, 2.40791463e-01, 6.33164038e-01, 7.97559123e-01,\n",
       "         8.38741871e-01, 9.74335601e-01, 3.15864736e-01, 9.50326281e-03,\n",
       "         2.07542738e-01, 2.91667255e-01, 8.64017897e-01, 4.49756324e-01,\n",
       "         6.52567529e-01, 4.60176723e-02, 3.89503833e-01, 2.43563190e-01,\n",
       "         7.62718153e-01, 1.74068408e-01, 4.38571784e-01, 1.39115298e-01,\n",
       "         6.22243542e-01, 7.99010333e-03, 3.36529846e-01, 6.68985462e-01,\n",
       "         1.02401391e-01, 3.69440728e-01, 2.29133234e-01, 6.25958916e-01,\n",
       "         6.71331924e-01, 5.87973750e-01, 9.87132593e-01, 7.82899251e-01],\n",
       "        [4.48300599e-01, 7.56760979e-01, 3.04247254e-01, 9.39956332e-01,\n",
       "         9.92678548e-01, 6.57480149e-01, 4.94903580e-01, 2.95496649e-01,\n",
       "         5.44839363e-01, 8.37362217e-01, 2.61485546e-01, 5.92795156e-01,\n",
       "         6.23758466e-01, 4.79719156e-01, 2.07665891e-02, 3.55573024e-01,\n",
       "         7.68220351e-01, 2.27440775e-01, 2.03987199e-01, 4.24551876e-01,\n",
       "         5.63663850e-01, 8.32109794e-02, 4.19624432e-01, 3.81301284e-01,\n",
       "         2.94250694e-01, 8.81811967e-01, 7.04241697e-01, 5.82064560e-01,\n",
       "         1.73415507e-01, 5.01698549e-01, 4.87382344e-01, 3.23972249e-01,\n",
       "         9.18748775e-01, 2.63241101e-01, 8.59485470e-01, 8.60612380e-01,\n",
       "         4.58771301e-01, 2.85462495e-01, 9.74683069e-01, 8.03735458e-01,\n",
       "         7.94475030e-01, 6.78037301e-01, 1.26591706e-01, 4.63562198e-01,\n",
       "         5.53058627e-01, 3.35972922e-02, 6.64789977e-01, 6.36766939e-01,\n",
       "         2.76968134e-03, 8.46386013e-01, 2.22115245e-01, 6.25993754e-01,\n",
       "         5.06002021e-01, 1.07149813e-01, 8.19273053e-01, 7.45870117e-01,\n",
       "         7.11174950e-01, 7.44144719e-01, 5.26555451e-01, 2.81611692e-01,\n",
       "         8.74213076e-01, 9.76708617e-02, 4.10961362e-01, 3.81810905e-01,\n",
       "         5.20861508e-01, 5.44527175e-01, 7.43508745e-01, 8.78661341e-01,\n",
       "         6.72548573e-01, 6.17869617e-01, 1.82219723e-01, 5.03116640e-01,\n",
       "         6.71544528e-01, 2.44798050e-01, 8.64447837e-01, 2.30646441e-01,\n",
       "         5.23976852e-01, 2.62452128e-01, 4.89613059e-02, 1.71553986e-01,\n",
       "         7.55434487e-01, 2.54334800e-02, 3.31775428e-01, 8.42498258e-01,\n",
       "         4.37509422e-01, 9.68207529e-03, 5.96986264e-01, 5.77822495e-01,\n",
       "         6.14189469e-01, 3.96198264e-01, 9.58365815e-01, 1.94518419e-02,\n",
       "         3.02903905e-01, 1.96360418e-01, 8.72854370e-01, 9.74799162e-01,\n",
       "         2.63003376e-01, 7.75907149e-01, 2.99285484e-01, 1.48183845e-01],\n",
       "        [9.05070437e-01, 5.57098402e-01, 8.02832321e-01, 2.17429217e-01,\n",
       "         6.79106314e-01, 3.30630613e-01, 7.12391287e-01, 8.89862130e-02,\n",
       "         7.83982605e-01, 1.28180547e-01, 1.29634561e-01, 5.46482258e-02,\n",
       "         6.03342854e-01, 3.45254979e-01, 4.09594644e-01, 3.85548023e-01,\n",
       "         1.12193017e-01, 9.10192317e-01, 8.44944183e-01, 7.12925374e-01,\n",
       "         6.85638375e-01, 7.38337541e-01, 7.73458318e-01, 3.93619123e-01,\n",
       "         8.43279390e-02, 2.44529588e-01, 6.74112345e-02, 1.40068528e-01,\n",
       "         9.25907671e-01, 5.81080617e-01, 5.54787913e-01, 4.00158323e-01,\n",
       "         6.23418442e-01, 7.05326887e-01, 8.30683293e-01, 5.81002116e-01,\n",
       "         1.42713136e-01, 8.63277623e-01, 3.03232284e-01, 7.44392598e-01,\n",
       "         3.17189031e-01, 9.80922353e-01, 3.34575246e-01, 5.66722821e-01,\n",
       "         3.82858870e-01, 8.26686887e-01, 5.19392742e-01, 3.67780128e-02,\n",
       "         9.10868216e-01, 2.53389475e-01, 8.59257079e-01, 1.44793654e-01,\n",
       "         6.98893062e-01, 7.80937935e-01, 3.46580809e-01, 5.07088560e-01,\n",
       "         2.42095935e-01, 2.37172470e-01, 5.08422305e-01, 8.92963379e-01,\n",
       "         2.18700066e-01, 3.40366789e-01, 6.65408934e-03, 8.28090701e-01,\n",
       "         4.27625055e-01, 4.70816839e-01, 4.48129195e-01, 5.41682524e-01,\n",
       "         4.95087563e-01, 4.33371455e-01, 1.76382360e-01, 7.30176376e-01,\n",
       "         7.31074408e-01, 1.97055573e-01, 2.59955469e-01, 6.04279437e-01,\n",
       "         8.73813567e-01, 4.80666461e-01, 1.61872353e-03, 1.47138106e-01,\n",
       "         1.40972756e-01, 5.71683705e-01, 8.26350877e-01, 9.45335070e-01,\n",
       "         4.82361817e-02, 9.86469394e-01, 1.43433049e-01, 5.65382787e-01,\n",
       "         4.27188882e-01, 2.56950817e-01, 3.86778549e-01, 9.27676899e-01,\n",
       "         4.42962265e-01, 7.97988701e-02, 9.65351294e-01, 6.64257357e-01,\n",
       "         2.96350952e-01, 9.05123945e-01, 2.63903069e-01, 3.08473564e-01]])]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Weight Matrix based on initial values for thetas\n",
    "weight_matrix = [np.random.rand(*theta) for theta in theta_structure]\n",
    "\n",
    "weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate arrays to flatten one by one\n",
    "initial_to_inner_thetas = np.hstack(weight_matrix[0]).squeeze()\n",
    "output_thetas = np.hstack(weight_matrix[1]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95202301, 0.63406304, 0.8106702 , ..., 0.90512395, 0.26390307,\n",
       "       0.30847356])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum the flattened arrays to get the intial thetas\n",
    "initial_thetas = np.hstack((initial_to_inner_thetas, output_thetas))\n",
    "\n",
    "initial_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos necesarios para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Array in Array of Arrays\n",
    "def inflate_matrixes(initial_thetas, shapes):\n",
    "    layers = len(shapes) + 1\n",
    "    sizes = [shape[0] * shape[1] for shape in shapes]\n",
    "    steps = np.zeros(layers, dtype=int)\n",
    "\n",
    "    for i in range(layers - 1):\n",
    "        steps[i + 1] = steps[i] + sizes[i]\n",
    "\n",
    "    return [\n",
    "        initial_thetas[steps[i]: steps[i + 1]].reshape(*shapes[i])\n",
    "        for i in range(layers - 1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistics Sigmoid Function (1/(1 + e^-x)) for each value in input Z\n",
    "def sigmoid(Z):\n",
    "    a = [(1 / (1 + np.exp(-x))) for x in Z]\n",
    "    return np.asarray(a).reshape(Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward Model with activation \n",
    "def feed_forward_model(thetas, X):\n",
    "    AL = [X]\n",
    "    \n",
    "    for i in range(len(thetas)):\n",
    "        AL.append(\n",
    "            sigmoid(\n",
    "                np.matmul(\n",
    "                    np.hstack((\n",
    "                        np.ones(len(X)).reshape(len(X), 1),\n",
    "                        AL[i]\n",
    "                    )),\n",
    "                    thetas[i].T\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    return AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost predicted-expected value\n",
    "def cost_predict(initial_thetas, shapes, X, Y):\n",
    "    ffm = feed_forward_model(\n",
    "        inflate_matrixes(initial_thetas, shapes),\n",
    "        X\n",
    "    )\n",
    "    ff_log = Y * np.log(ffm[-1]) + (1 - Y) * np.log(1 - ffm[-1])\n",
    "    return -ff_log.sum() / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gradient based on thetas, neural network shape and inputs(X, Y)\n",
    "def model_backpropagation(initial_thetas, shapes, X, Y):\n",
    "    m, layers = len(X), len(shapes) + 1\n",
    "    thetas = inflate_matrixes(initial_thetas, shapes)\n",
    "    ffm = feed_forward_model(thetas, X)\n",
    "    deltas = [*range(layers - 1), ffm[-1] - Y]\n",
    "\n",
    "    for i in range(layers - 2, 0, -1):\n",
    "        deltas[i] =  (deltas[i + 1] \n",
    "                      @ \n",
    "                      np.delete(thetas[i], 0, 1)) * (ffm[i] * (1 - ffm[i]))\n",
    "\n",
    "    propagate = []\n",
    "    for n in range(layers - 1):\n",
    "        propagate.append(\n",
    "            (deltas[n + 1].T \n",
    "            @ \n",
    "            np.hstack((\n",
    "                np.ones(len(ffm[n])).reshape(len(ffm[n]), 1),\n",
    "                ffm[n]\n",
    "            ))) / m\n",
    "        )\n",
    "\n",
    "    propagate = np.asarray(propagate)\n",
    "    \n",
    "    input_to_inner_deltas = np.hstack(propagate[0]).squeeze()\n",
    "    output_deltas = np.hstack(propagate[1]).squeeze()\n",
    "    \n",
    "    return np.hstack((input_to_inner_deltas, output_deltas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la data, obtener el array de thetas entrenados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No correr esta parte del codigo, a mi me tardo 18 horas en terminar con 1848 iteraciones lo cual retorno un 85.33% de precision con el Test_Set <br/>Por seguridad le cambie el No. de iteraciones a 10 y cambie el nombre del archivo a guardar por si lo quieren correr, pero va a dar con precision del 7-9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-221-6c088f2837e7>:7: RuntimeWarning: divide by zero encountered in log\n",
      "  ff_log = Y * np.log(ffm[-1]) + (1 - Y) * np.log(1 - ffm[-1])\n",
      "<ipython-input-221-6c088f2837e7>:7: RuntimeWarning: invalid value encountered in multiply\n",
      "  ff_log = Y * np.log(ffm[-1]) + (1 - Y) * np.log(1 - ffm[-1])\n"
     ]
    }
   ],
   "source": [
    "# Inject initial_thetas and get optimized trained thetas \n",
    "trained = optimize.minimize(\n",
    "    fun = cost_predict,\n",
    "    x0 = initial_thetas,\n",
    "    args = (theta_structure, X, Y),\n",
    "    method = 'L-BFGS-B',\n",
    "    jac = model_backpropagation,\n",
    "    options = {'disp': True, 'maxiter': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Optimized thetas into array\n",
    "np.savetxt('trained_thetas_10.txt', trained.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizar las thetas entrenadas para predecir la data del Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained thetas from file into an array\n",
    "optimized_thetas = np.loadtxt(\"trained_thetas_1848.txt\")\n",
    "# Transform array into array of arrays using the Neural Network Structure\n",
    "thetas = inflate_matrixes(optimized_thetas, theta_structure)\n",
    "\n",
    "# Organize dataset into arrays \n",
    "X_test = test_set.iloc[:, 1:] / 1000.0\n",
    "m, n = X_test.shape\n",
    "y_test = np.asarray(test_set.iloc[:, 0])\n",
    "y_test = y_test.reshape(m, 1)\n",
    "Y_test = (y_test == np.array(range(10))).astype(int)\n",
    "\n",
    "# Test the data based on trained thetas matrix\n",
    "ffm_trained = feed_forward_model(thetas, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.33 % of precision got, running with Testing Set\n"
     ]
    }
   ],
   "source": [
    "predicted = 0\n",
    "predicted_values = []\n",
    "true_values = []\n",
    "\n",
    "# Save Predicted Values in array\n",
    "for prediction in ffm_trained[-1]:\n",
    "    predicted_values.append(np.where(prediction == np.amax(prediction))[0])\n",
    "\n",
    "# Save Real Values in array\n",
    "for true_value in Y_test:\n",
    "    true_values.append(np.where(true_value == np.amax(true_value))[0])\n",
    "\n",
    "# Compare values from both arrays to find correct values\n",
    "for value in range(len(X_test)):\n",
    "    if predicted_values[value].item(0) == true_values[value].item(0):\n",
    "        predicted += 1\n",
    "\n",
    "print(round(100 * predicted/len(X_test), 2), \"% of precision got, running with Testing Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 85.33% de Precision con el Testing Set, se obtuvo mas del 87% utilizando el  dataset de entrenamiento pero no vale tanto la pena mostrar porque obviamente el Training Set elevara los valores predecidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para un poco de discusion podemos visualizar lo que la falta iteraciones en el entrenamiento afecta al modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.19 % of precision got, running with Testing Set on Poorly Trained NN\n"
     ]
    }
   ],
   "source": [
    "# Load the trained thetas from file into an array\n",
    "optimized_thetas_try = np.loadtxt(\"trained_thetas_1200.txt\")\n",
    "# Transform array into array of arrays using the Neural Network Structure\n",
    "thetas_try = inflate_matrixes(optimized_thetas_try, theta_structure)\n",
    "\n",
    "# Test the data based on trained thetas matrix\n",
    "ffm_trained_try = feed_forward_model(thetas_try, X_test)\n",
    "\n",
    "predicted_try = 0\n",
    "predicted_values_try = []\n",
    "true_values_try = []\n",
    "\n",
    "# Save Predicted Values in array\n",
    "for prediction in ffm_trained_try[-1]:\n",
    "    predicted_values_try.append(np.where(prediction == np.amax(prediction))[0])\n",
    "\n",
    "# Save Real Values in array\n",
    "for true_value in Y_test:\n",
    "    true_values_try.append(np.where(true_value == np.amax(true_value))[0])\n",
    "\n",
    "# Compare values from both arrays to find correct values\n",
    "for value in range(len(X_test)):\n",
    "    if predicted_values_try[value].item(0) == true_values_try[value].item(0):\n",
    "        predicted_try += 1\n",
    "\n",
    "print(round(100 * predicted_try/len(X_test), 2), \"% of precision got, running with Testing Set on Poorly Trained NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos analizar luego de esto que nuestro modelo es bastante de fiar para la prediccion de la base de datos minst, los algoritmos de Feed Forward y Back Propagation son los correctos, sin embargo, se podria encontrar aun muchos metodos para optimizarlos. En total, para lograr un 85.33 porciento de fidelidad del algoritmo con el Testing Set se requirieron 1848 iteraciones de optimize.minimize de scipy, lo cual duro un aproximado de 18 horas corriendo en una maquina core i7 de 7ma generacion, 16GB de RAM... Antes se realizaron bastantes intentos mas, intentando optimizar el algoritmo, casi todas las veces sin exito y regresando a versiones muy parecidas del original de Samuel. Una de las cosas que se pueden discutir, es lo que realiza el entrenamiento de la red y su impacto final, se empezo desde 300 iteraciones, unas 2-3 horas obteniendo 40-45% de precision, luego se aumento a 500 subiendo a 60-69% de presicion. Desde ese momento se analizo que se necesitaban muchas mas iteraciones, corri con 1200 pensando que lograria la cantidad correcta, arriba pueden ver el resultado. Finalmente corri con 2000, en donde al llegar a 1851 iteraciones el algoritmo empezo a reportar analizar sobre valores de f = NaN, y tardarse alrededor de 2-5minutos por iteracion. Se opto por repetir con 1848 iteraciones creyendo haber llegado a un error de Bias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
